{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##basic setting\n",
    "\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "importlib.reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "home_dir =os.getcwd()\n",
    "bin_dir = os.path.join(home_dir, 'bin')\n",
    "model_dir = os.path.join(home_dir, 'model')\n",
    "conf_dir = os.path.join(home_dir, 'conf')\n",
    "data_dir = os.path.join(home_dir, 'data')\n",
    "lib_dir = os.path.join(home_dir, 'lib')\n",
    "log_dir = os.path.join(home_dir, 'log')\n",
    "sys.path.append(lib_dir)\n",
    "\n",
    "import tokenFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\liuqimin\\\\nn-handwrite'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出单元激活函数\n",
    "def softmax(x):\n",
    "    x = np.array(x)\n",
    "    max_x = np.max(x)\n",
    "    return np.exp(x-max_x) / np.sum(np.exp(x-max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN:\n",
    "    def __init__(self, data_dim, hidden_dim=100, bptt_back=4):\n",
    "        # data_dim: 词向量维度，即词典长度; hidden_dim: 隐单元维度; bptt_back: 反向传播回传时间长度\n",
    "        self.data_dim = data_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_back = bptt_back\n",
    "\n",
    "        # 初始化权重向量 U， W， V; U为输入权重; W为递归权重; V为输出权重\n",
    "        self.U = np.random.uniform(-np.sqrt(1.0/self.data_dim), np.sqrt(1.0/self.data_dim),\n",
    "                                   (self.hidden_dim, self.data_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1.0/self.hidden_dim), np.sqrt(1.0/self.hidden_dim),\n",
    "                                   (self.hidden_dim, self.hidden_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1.0/self.hidden_dim), np.sqrt(1.0/self.hidden_dim),\n",
    "                                   (self.data_dim, self.hidden_dim))\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        # 向量时间长度\n",
    "        T = len(x)\n",
    "\n",
    "        # 初始化状态向量, s包含额外的初始状态 s[-1]\n",
    "        s = np.zeros((T+1, self.hidden_dim))\n",
    "        o = np.zeros((T, self.data_dim))\n",
    "\n",
    "        for t in range(T):\n",
    "            s[t] = np.tanh(self.U[:, x[t]] + self.W.dot(s[t-1]))\n",
    "            o[t] = softmax(self.V.dot(s[t]))\n",
    "\n",
    "        return [o, s]\n",
    "\n",
    "    # 预测输出\n",
    "    def predict(self, x):\n",
    "        o, s = self.forward(x)\n",
    "        pre_y = np.argmax(o, axis=1)\n",
    "        return pre_y\n",
    "\n",
    "    # 计算损失， softmax损失函数， (x,y)为多个样本\n",
    "    def loss(self, x, y):\n",
    "        cost = 0\n",
    "        for i in range(len(y)):\n",
    "            o, s = self.forward(x[i])\n",
    "            # 取出 y[i] 中每一时刻对应的预测值\n",
    "            pre_yi = o[range(len(y[i])), y[i]]\n",
    "            cost -= np.sum(np.log(pre_yi))\n",
    "\n",
    "        # 统计所有y中词的个数, 计算平均损失\n",
    "        N = np.sum([len(yi) for yi in y])\n",
    "        ave_loss = cost / N\n",
    "\n",
    "        return ave_loss\n",
    "\n",
    "    # 求梯度, (x,y)为一个样本\n",
    "    def bptt(self, x, y):\n",
    "        dU = np.zeros(self.U.shape)\n",
    "        dW = np.zeros(self.W.shape)\n",
    "        dV = np.zeros(self.V.shape)\n",
    "\n",
    "        o, s = self.forward(x)\n",
    "        delta_o = o\n",
    "        delta_o[range(len(y)), y] -= 1\n",
    "\n",
    "        for t in np.arange(len(y))[::-1]:\n",
    "            # 梯度沿输出层向输入层的传播\n",
    "            dV += delta_o[t].reshape(-1, 1) * s[t].reshape(1, -1)  # self.data_dim * self.hidden_dim\n",
    "            delta_t = delta_o[t].reshape(1, -1).dot(self.V) * ((1 - s[t-1]**2).reshape(1, -1)) # 1 * self.hidden_dim\n",
    "\n",
    "            # 梯度沿时间t的传播\n",
    "            for bpt_t in np.arange(np.max([0, t-self.bptt_back]), t+1)[::-1]:\n",
    "                dW += delta_t.T.dot(s[bpt_t-1].reshape(1, -1))\n",
    "                dU[:, x[bpt_t]] = dU[:, x[bpt_t]] + delta_t\n",
    "\n",
    "                delta_t = delta_t.dot(self.W.T) * (1 - s[bpt_t-1]**2)\n",
    "\n",
    "        return [dU, dW, dV]\n",
    "\n",
    "    # 计算梯度\n",
    "    def sgd_step(self, x, y, learning_rate):\n",
    "        dU, dW, dV = self.bptt(x, y)\n",
    "\n",
    "        self.U -= learning_rate * dU\n",
    "        self.W -= learning_rate * dW\n",
    "        self.V -= learning_rate * dV\n",
    "\n",
    "    # 训练RNN\n",
    "    def train(self, X_train, y_train, learning_rate=0.005, n_epoch=5):\n",
    "        losses = []\n",
    "        num_examples = 0\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            for i in range(len(y_train)):\n",
    "                self.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "                num_examples += 1\n",
    "\n",
    "            loss = self.loss(X_train, y_train)\n",
    "            losses.append(loss)\n",
    "            print( 'epoch {0}: loss = {1}'.format(epoch+1, loss) )\n",
    "            # 若损失增加，降低学习率\n",
    "            if len(losses) > 1 and losses[-1] > losses[-2]:\n",
    "                learning_rate *= 0.5\n",
    "                print( 'decrease learning_rate to', learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_token = 'UNKNOWN_TOKEN'\n",
    "start_token = 'START_TOKEN'\n",
    "end_token = 'END_TOKEN'\n",
    "\n",
    "def generate_text(rnn, dict_words, index_of_words):\n",
    "    # dict_words: type list; index_of_words: type dict\n",
    "    sent = [index_of_words[start_token]]\n",
    "    # 预测新词，知道句子的结束(END_TOKEN)\n",
    "    while not sent[-1] == index_of_words[end_token]:\n",
    "        next_probs, _ = rnn.forward(sent)\n",
    "        sample_word = index_of_words[unknown_token]\n",
    "\n",
    "        # 按预测输出分布进行采样，得到新的词\n",
    "        while sample_word == index_of_words[unknown_token]:\n",
    "            samples = np.random.multinomial(1, next_probs[-1])\n",
    "            sample_word = np.argmax(samples)\n",
    "        # 将新生成的有含义的词(即不为UNKNOWN_TOKEN的词)加入句子\n",
    "        sent.append(sample_word)\n",
    "\n",
    "    new_sent = [dict_words[i] for i in sent[1:-1]]\n",
    "    new_sent_str = ' '.join(new_sent)\n",
    "\n",
    "    return new_sent_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 79170 sentences.\n",
      "Get 65408 words.\n"
     ]
    }
   ],
   "source": [
    "file_path = r'data/reddit-comments-2015-08.csv'\n",
    "dict_size = 8000\n",
    "myTokenFile = tokenFile.tokenFile2vector(file_path, dict_size)\n",
    "X_train, y_train, dict_words, index_of_words = myTokenFile.get_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = myRNN(dict_size, hidden_dim=100, bptt_back=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.train(X_train[:200], y_train[:200], learning_rate=0.005, n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_str = generate_text(rnn, dict_words, index_of_words)\n",
    "print ('Generate sentence:', sent_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
